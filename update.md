# 更新日志
* v0.2.5
   * 警告，本次新增了openai依赖库，非容器部署请拉取安装依赖库
   * 首发适配vertex快速模式，在配置key后，访问支持快速模式的模型时，将首先使用快速模式的key访问
   * 快速模式仅支持gemini-2.0-flash-001,gemini-2.0-flash-lite-001,gemini-2.5-pro-preview-03-25,gemini-2.5-flash-preview-04-17
   * 更新vertex模式ui，前端界面现在可以开启关闭假流式，快速模式与替换快速模式key
   * 新增环境变量`VERTEX_EXPRESS_API_KEY`，为快速模式key
   * 修复若干bug，提高系统稳定性

* v0.2.4
   * 为vertex模式适配gemini-2.5-pro-preview-05-06
   * 修复负载均衡模式bug
   * 优化统计相关计算，占用性能更少
   * 修复若干bug，提高系统稳定性

* v0.2.3
   * 优化了负载均衡策略
   * 重构了持久化模块
   * 新增了模型白名单和请求头白名单模式，对应环境变量`WHITELIST_MODELS`和`WHITELIST_USER_AGENT`
   * 修复了夜间模式下文字颜色显示不正确的问题
   * 前端新增了对 API Key 可用性的检查功能
   * 修复了若干已知问题
* v0.2.2
    * 实现函数调用支持，包括流式和非流式函数调用
    * 修复了dockerfile不使用uv的问题
    * 修复了SKIP_CHECK_API_KEY环境变量相关问题
    * 采用最后8条消息计算缓存键，提升缓存效率
    * 新增key后，如果之前的模型列表为空，会自动拉取模型列表，因此现在不需要在环境变量中预先添加key，可以直接在前端界面添加使用
* v0.2.1beta
    * 为vps/本地部署用户提供持久化支持（测试版），现在所有的配置选项与请求记录都可以持久化存储
    * 为前端添加API实时调用统计图表
    * 为前端新增添加API秘钥功能（注意，如果您没有配置持久化，在这里添加的key在项目重启后会丢失）
    * 添加对函数调用的支持
    * 新增环境变量`STORAGE_DIR`，为持久化存储目录，默认为`/hajimi/settings/`
    * 新增环境变量`ENABLE_STORAGE`，为是否启用持久化，默认为`false` 
    * 修复若干bug，提高系统稳定性
* v0.2.0
    * ui全面焕新，更动态更好看，为api key显示添加分页，适配拥有大量key的用户
    * 隔离vertex模式与ai studio模式日志，ai studio玩家再也不会看到vertex的报错了
    * 拆分web ui密码与连接密码，现在可以安全的把反代分享给其他人了
    * 新增环境变量`WEB_PASSWORD`，为web ui修改设置密码，默认值为环境变量`PASSWORD`的值
    * 修复若干bug，增加系统稳定性
* v0.1.7
    * 添加token计数器，现在可以在前端看到每一个api使用的token数与单模型使用的token数量了
    * 为2.5flash模型适配`thinkingBudget`参数，用户只需在附加参数中添加`- thinking_budget : 1024`即可调整
    * 修复在报错中错误漏出key的问题
    * 为并发缓存功能实现缓存键值计算切换，用户可选择使用最后八条消息或全部消息计算缓存
    * 新增环境变量`PRECISE_CACHE`，为切换缓存计算方法，默认为`false`
    * 修复若干bug
* v0.1.6
    * 为并发模式提供缓存，并发中除了返回的成功请求，其他成功请求将被缓存，若下次请求与本次请求一致，将首先使用缓存内容
    * 为请求添加硬限制，超过每日限定次数的key将不再发送请求，若所有key都达到次数限制，将随机选择一个key请求
    * 添加空响应计数，单次请求空响应重试超过一定次数将直接跳出
    * 修复联网模式bug（感谢**yoolieer**），现在能够正常的启用停用联网模式了
    * 新增环境变量`MAX_EMPTY_RESPONSES`，为空响应重试次数，默认为5
    * 修复若干bug
* v0.1.5
    * 实现vertex热切换，现在在前端面板就可以切换vertex模式与ai studio模式了
    * 为vertex模式实现假流式，环境变量与ai studio模式的假流式相同，均为`FAKE_STREAMING`
    * 优化前端界面
    * 修复若干bug
* v0.1.4beta
    * 为大部分配置项适配热更新，可实时调整配置
    * 前端界面新增适配热更新相关ui界面，可直接调整配置（在前端界面修改的数据在重启后会失效）
    * 适配 vertex ai（基于gzzhongqi/vertex2openai项目开发），在启用vertex模式并配置vertex凭证后，项目将切换为vertex请求模式
    * 新增环境变量`ENABLE_VERTEX`用于启用vertex模式，初始默认为false
    * 新增环境变量`GOOGLE_CREDENTIALS_JSON`用于配置vertex凭证，默认为空
* v0.1.3
    * 应对谷歌加强封锁紧急更新，优化连接逻辑，减少错误发生
    * 修复了在非流式模式下日志暴露key的问题
    * 修复前端界面联网模式无法正确显示
    * 修复前端界面伪装模式字符数量无法正确显示
* v0.1.2beta
    * 为非流式和假流式传输模式新增动态并发功能，用户可自定义初始并发请求数。在全部请求失败时，系统将增加并发请求数，直至达到最大并发请求数。当收到请求时，程序会首先尝试并发处理，若并发处理失败，则根据设定逐步增加并发数。
    * 重构请求处理逻辑，现在能够正确处理各个模式的请求。
    * 新增手动重置统计数据按钮，用户可在点击按钮后输入password重置统计数据
    * 前端环境配置栏目将展示更多功能配置，同时展示卡可折叠
    * 修改重置统计数据时间为北京时间15点
    * 修复若干bug
    * 新增环境变量`CONCURRENT_REQUESTS`用于设置默认的并发请求数，初始默认值为1。
    * 新增环境变量`INCREASE_CONCURRENT_ON_FAILURE`用于设置当请求失败时增加的并发请求数，初始默认值为1。
    * 新增环境变量`MAX_CONCURRENT_REQUESTS`用于设置允许的最大并发请求数，初始默认值为3。
*   v0.1.1
    * 新增联网模式,为所有gemini2.x模型提供联网能力，在模型列表中选择-search后缀的模型启用
    * 新增环境变量`SEARCH_MODE`是否启用联网模式，默认为true
    * 新增环境变量`SEARCH_PROMPT`为联网模式提示词，默认为`（使用搜索工具联网搜索，需要在content中结合搜索内容）`
*   v0.1.0
    * 使用vue重写前端界面，适配移动端
    * 前端界面添加黑夜模式
    * 支持为多模态模型上传图片
    * 可用秘钥数量将异步更新，防止阻塞进程
    * 这次真能北京时间16点自动重置统计数据了
    * 为api秘钥使用统计新增模型使用统计，可分别统计使用不同模型的次数
    * 修改默认api可用次数为100次
    * 降低默认伪装信息长度为5，以减少对上下文的污染
*   v0.0.5beta
    * 新增"**伪装信息**功能，默认开启，可在转发消息中添加随机字符串伪装消息，防止被检测
    * 修复若干bug
    * 为前端界面新增**功能配置**栏目，可检查功能是否开启
    * 北京时间16点自动重置统计数据
    * 在环境变量中新增`RANDOM_STRING`，是否启用伪装信息，默认值为true
    * 在环境变量中新增`RANDOM_STRING_LENGTH`，伪装信息长度，默认为20
    * 为git用户提供单独的`Dockerfile_git`
*   v0.0.4
    * 修改版本更新逻辑，现在为每四小时检查一次版本更新
    * 前端界面所有数据数据实现动态更新
    * 新增**单api使用次数统计**，在原API调用统计下方新增可折叠的单api使用次数统计，同时提供进度条查看剩余使用次数
    * 在环境变量中新增`API_KEY_DAILY_LIMIT`，为单api 24小时最大使用次数，默认值为25
    * 在环境变量中新增`BLOCKED_MODELS`，为需要屏蔽的模型名称，多个模型用英文逗号分隔
*   v0.0.3beta
    * 完善了客户端断开连接的处理逻辑（感谢[@warming-afternoon](https://github.com/warming-afternoon)）
    * 新增"假流式传输模式"，该模式默认开启，以解决在某些情况下客户端断开连接的问题。如需关闭，请将环境变量 `FAKE_STREAMING` 设置为 `false`。
*   v0.0.2 修复了在log中错误暴露apikey的问题，修改了客户端断开连接的处理逻辑（感谢[@warming-afternoon](https://github.com/warming-afternoon)）
